{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('../')\n",
    "from config.basic import ConfigBasic\n",
    "from networks.util import prepare_model\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "# Dataset\n",
    "cfg = ConfigBasic()\n",
    "cfg.dataset = 'aiims'\n",
    "cfg.setting = 'D'\n",
    "cfg.fold = 4\n",
    "\n",
    "cfg.logscale = False\n",
    "cfg.set_dataset()\n",
    "cfg.tau = 1\n",
    "\n",
    "# Model\n",
    "cfg.model = 'GOL'\n",
    "cfg.backbone = 'vgg16v2norm'\n",
    "cfg.metric = 'L2'\n",
    "cfg.k = np.arange(2, 50, 2)\n",
    "cfg.epochs = 40\n",
    "cfg.scheduler = 'cosine'\n",
    "cfg.lr_decay_epochs = [100, 200, 300]\n",
    "cfg.period = 3\n",
    "\n",
    "cfg.margin = 0.25\n",
    "cfg.ref_mode = 'flex'\n",
    "cfg.ref_point_num = 10  # 60 Fold1, 58 Fold0 setting D // 56 setting c // 58 setting B // 55 setting A\n",
    "cfg.drct_wieght = 1\n",
    "cfg.start_norm = True\n",
    "cfg.learning_rate = 0.0001\n",
    "\n",
    "# Log\n",
    "#cfg.wandb = False\n",
    "#cfg.experiment_name = 'EXP_NAME'\n",
    "#cfg.save_folder = f'../../RESULT_FOLDER_NAME/{cfg.dataset}/setting{cfg.setting}/{cfg.experiment_name}/PREFIX_{cfg.margin}_tau{cfg.tau}_F{cfg.fold}_{cfg.model}_{cfg.backbone}_{get_current_time()}'\n",
    "#make_dir(cfg.save_folder)\n",
    "\n",
    "cfg.n_gpu = torch.cuda.device_count()\n",
    "cfg.num_workers = 1\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, split, ind=None) -> None:\n",
    "            super().__init__()\n",
    "            self.ind = ind\n",
    "            self.model = prepare_model(cfg)\n",
    "            self.model.load_state_dict(torch.load(\"models/split_\"+split+\"/0/model.tar\"))\n",
    "            \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        #dist_mat = torch.matmul(x[0], self.model.ref_points[self.ind].T)\n",
    "        dist_mat = torch.matmul(x, self.model.ref_points.T)\n",
    "        #return torch.stack([dist_mat,])\n",
    "        return dist_mat\n",
    "    \n",
    "class NeuralNetwork_pred(nn.Module):\n",
    "    def __init__(self, split, ind=None) -> None:\n",
    "            super().__init__()\n",
    "            self.ind = ind\n",
    "            self.model = prepare_model(cfg)\n",
    "            self.model.load_state_dict(torch.load(\"models/split_\"+split+\"/0/model.tar\"))\n",
    "            \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        #dist_mat = torch.matmul(x[0], self.model.ref_points[self.ind].T)\n",
    "        #dist_mat = torch.matmul(x, self.model.ref_points.T)\n",
    "        #return torch.stack([dist_mat,])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from captum.attr import GuidedGradCam , GuidedBackprop, LRP, LayerGradCam, LayerAttribution\n",
    "\n",
    "from captum.attr._utils.lrp_rules import EpsilonRule, PropagationRule\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "\n",
    "def get_box_params( index, src=\"/home/raman/Work/Dataset/boxes.json\"):\n",
    "    data = json.load(open(src , 'r'))\n",
    "    box = data[str(index)]\n",
    "    # h, w = data[\"imageHeight\"], data[\"imageWidth\"]\n",
    "    return box\n",
    "\n",
    "def homographic_transformation(file, index,side = 300):\n",
    "    \n",
    "    box = get_box_params(index)\n",
    "    \n",
    "    # Define the four corners of the rotated box\n",
    "    rotated_box = np.array(box, dtype=np.float32)\n",
    "\n",
    "    # Define the four corners of the target box\n",
    "    target_box = np.array([(0, 0), (side, 0), (side, side), (0, side)], dtype=np.float32)\n",
    "\n",
    "    # Calculate the homography matrix\n",
    "    H, _ = cv2.findHomography(rotated_box, target_box)\n",
    "\n",
    "    # Load an image\n",
    "    image = cv2.imread(file)\n",
    "\n",
    "    # Apply the homography transformation to the image\n",
    "    transformed_image = cv2.warpPerspective(image, H, (side, side))\n",
    "    transformed_image = cv2.cvtColor(transformed_image, cv2.COLOR_BGRA2RGB)\n",
    "    #import ipdb\n",
    "    #ipdb.set_trace()\n",
    "    return Image.fromarray(transformed_image).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with (open(\"outputs_gol.pickle\", \"rb\")) as openfile:\n",
    "    outputs = pickle.load(openfile)\n",
    "with (open(\"labels_gol.pickle\", \"rb\")) as openfile:\n",
    "    labels = pickle.load(openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "preds = {}\n",
    "pred_labels = {}\n",
    "cls = 1\n",
    "outputs = [i[0] for i in outputs]\n",
    "labels = np.array(labels)\n",
    "predictions = []\n",
    "def get_visulaization(exp):\n",
    "    fld = \"_\".join(exp.split(\"_\")[2:])\n",
    "    save_addr = \"/home/raman/Work/Code/drilling/GOL/train/grad_cam_class_\"+str(cls)+\"/\"\n",
    "    Path(save_addr).mkdir(parents=True, exist_ok=True)\n",
    "    df=pd.read_csv('/home/raman/Work/Dataset/new_score_split.csv')\n",
    "    \n",
    "    for fold in range(1):\n",
    "        model = model = NeuralNetwork_pred(str(fold), cls)\n",
    "        model.eval()\n",
    "        # val_dataset = AgeDB(data_dir=str(fold), df=None, img_size=224, group=fld, split='val')\n",
    "        # val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False,\n",
    "        #                     num_workers=32, pin_memory=True, drop_last=False)\n",
    "        #model.model.lnorm.rule = EpsilonRule()\n",
    "        #print(model.model.lnorm.rule)\n",
    "        target_layer = model.model.encoder.features[-1]\n",
    "        #cap_vis = LayerGradCam(model, target_layer)\n",
    "        filtered_df = df[df['Split'] == fold]\n",
    "        index_list = filtered_df['Index'].tolist()\n",
    "        labs = filtered_df['GT'].tolist()\n",
    "        # for img_, label, weight, file in val_loader:\n",
    "        for ind, index in enumerate(index_list):\n",
    "            file='/home/raman/Work/Dataset/Images/'+str(index)+'.png'\n",
    "            img_=homographic_transformation(file,index)\n",
    "\n",
    "            transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0,0,0], std=[1,1,1]),\n",
    "            ])\n",
    "            img_ = transform(img_)\n",
    "            pred = model(torch.stack([img_,]))\n",
    "            \n",
    "            cs = torch.matmul(torch.stack(outputs), pred[0].T)\n",
    "            vals, inds = torch.topk(cs, 5)\n",
    "            pred = round(sum(np.array(labels)[inds])/5)\n",
    "            predictions.append(pred)\n",
    "\n",
    "            #outputs[index] = output.detach()\n",
    "            #labels[index] = labs[ind]\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raman/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/raman/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_381885/654284999.py:43: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2981.)\n",
      "  cs = torch.matmul(torch.stack(outputs), pred[0].T)\n"
     ]
    }
   ],
   "source": [
    "pred = get_visulaization(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
